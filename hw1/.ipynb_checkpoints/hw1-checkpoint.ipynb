{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №1\n",
    "\n",
    "В этом домашнем задании вы познакомитесь с pytorch сами и сможете попрактиковаться в его применении. \n",
    "\n",
    "#### План:\n",
    "\n",
    "1. Простейшие операции в pytorch\n",
    "2. Пишем Adam и применяем его к ручной модели\n",
    "3. Обучаем свою первую нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простейшие операции на pytorch (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Cоздайте два случайных тензора (двумерных, не квадратных):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(4, 5)\n",
    "y = torch.rand(4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Умножьте их друг на друга, результат запишите в третий тензор без использования оператора `=`, для создания третьего тензора предлагается использовать `torch.empty`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2695, 0.0446, 0.8428, 0.2461, 0.2080],\n",
       "        [0.1278, 0.1517, 0.1609, 0.0965, 0.2172],\n",
       "        [0.2786, 0.6177, 0.8165, 0.5948, 0.5419],\n",
       "        [0.0254, 0.0265, 0.5177, 0.0035, 0.4834]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.empty(4, 5)\n",
    "torch.mul(x, y, out=z)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Реализуйте ReLU используя только pytorch, примените его к тензору `x` (запрещено использование модулей torch.nn и его подмодулей, а также функции torch.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_forward(x):\n",
    "    def func(x):\n",
    "        if x < 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    return x.apply_(func)\n",
    "    \n",
    "\n",
    "assert torch.all(F.relu(x) == relu_forward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Сделайте тоже самое c ELU (запрещено использование модулей torch.nn и его подмодулей):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu_forward(x, alpha):\n",
    "    def func(x, alpha):\n",
    "        if x < 0:\n",
    "            return alpha * (exp(x) - 1)\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    return x.apply_(lambda x: func(x, alpha))\n",
    "    \n",
    "\n",
    "assert torch.allclose(\n",
    "    F.elu(x, 0.01),\n",
    "    elu_forward(x, 0.01), \n",
    "    1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: LeakyReLU (запрещено использование модулей torch.nn и его подмодулей):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu_forward(x):\n",
    "    def func(x):\n",
    "        if x < 0:\n",
    "            return 0.01 * x\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    return x.apply_(func)\n",
    "\n",
    "assert torch.all(F.leaky_relu(x) == lrelu_forward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Теперь перейдем к немного более современным функциям активаций, например Mish, напомним как она выглядит:\n",
    "\n",
    "$$x * tanh(ln(1+e^x))$$\n",
    "\n",
    "(запрещено использование модулей torch.nn и его подмодулей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(x):\n",
    "    def func(x):\n",
    "        return x * math.tanh(math.log(1 + math.exp(x)))\n",
    "    \n",
    "    return x.apply_(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(\n",
    "    mish(torch.tensor([1, 1, 1], dtype=torch.float32)), \n",
    "    torch.tensor([0.8651, 0.8651, 0.8651]), \n",
    "    atol=1e-4\n",
    ")\n",
    "\n",
    "assert torch.allclose(\n",
    "    mish(torch.tensor([0.6376, 0.4021, 0.6656, 0.3726], dtype=torch.float64)), \n",
    "    torch.tensor([0.5014, 0.2908, 0.5280, 0.2663], dtype=torch.float64), \n",
    "    atol=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Теперь реализуем swish, напомним как она выглядит:\n",
    "\n",
    "$$x * \\sigma(x)$$\n",
    "\n",
    "(запрещено использование модулей torch.nn и его подмодулей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    def func(x):\n",
    "        return x / (1 + math.exp(-x))\n",
    "    \n",
    "    return x.apply_(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(\n",
    "    swish(torch.tensor([1, 1, 1], dtype=torch.float32)), \n",
    "    torch.tensor([0.7311, 0.7311, 0.7311]), \n",
    "    atol=1e-4\n",
    ")\n",
    "\n",
    "assert torch.allclose(\n",
    "    swish(torch.tensor([0.6376, 0.4021, 0.6656, 0.3726], dtype=torch.float64)), \n",
    "    torch.tensor([0.4171, 0.2409, 0.4396, 0.2206], dtype=torch.float64), \n",
    "    atol=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пишем Adam и применяем его к логистической регрессии (4 балла)\n",
    "\n",
    "\n",
    "В данной секции вам нужно сделать две вещи: \n",
    "\n",
    "1. Написать свой собственный оптимизатор подобно тому, который мы писали на семинаре\n",
    "2. Обучить логистическую регрессию побатчево на картинках из датасета \n",
    "\n",
    "\n",
    "#### Adam\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "g &=& \\frac{1}{m}\\nabla_w \\sum_i L(f(x_{i};w), y_{i}) \\\\\n",
    "m &=& \\beta_1 m + (1 - \\beta_1) g \\\\\n",
    "v &=& \\beta_2 v + (1 - \\beta_2) diag(gg^{T}) \\\\\n",
    "\\hat{m} &=& \\frac{m}{1 - \\beta_1^{t}} \\\\\n",
    "\\hat{v} &=& \\frac{v}{1 - \\beta_2^{t}} \\\\\n",
    "w &=& w - \\frac{\\eta}{\\sqrt{\\hat{v} + \\epsilon}} \\odot \\hat{m}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# абстрактный класс, не обращайте внимания\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "class InClassOptimizer(Optimizer):\n",
    "    def step(self):\n",
    "        \"\"\"Perform single optimization step.\"\"\"\n",
    "        with torch.no_grad(): # выключим градиенты\n",
    "            for group in self.param_groups:\n",
    "                self._group_step(group)\n",
    "\n",
    "    def _group_step(self, group):\n",
    "        # group ~ dict[str, ...]\n",
    "        \"\"\"\n",
    "        Private helper function to perform\n",
    "        single optimization step on model parameters.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Напишите свою реализацию Adam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(InClassOptimizer):\n",
    "    def __init__(self, params, lr=0.001, eps=1e-13, beta_1=0.9, beta_2=0.999):\n",
    "        defaults = dict(lr=lr, eps=eps, beta_1=beta_1, beta_2=beta_2)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    def _group_step(self, group):\n",
    "        # One group contains information about values passed in init\n",
    "        # and model parameters to update\n",
    "        lr = group['lr']\n",
    "        eps = group['eps']\n",
    "        beta_1 = group['beta_1']\n",
    "        beta_2 = group['beta_2']\n",
    "        for param in filter(lambda x: x.grad is not None, group['params']):\n",
    "            pass\n",
    "\n",
    "    def _get_adam_buffer(self, param):\n",
    "        \"\"\"\n",
    "        Get accumulated gradients for Adam.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        param : `torch.Tensor`, required\n",
    "            Model parameter to get accumulated gradeints for Adagrad.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Accumulated Adam gradients for parameter.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _init_adam_buffer(self, param):\n",
    "        \"\"\"\n",
    "        Initialize accumulated gradeints for adam.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        param : `torch.Tensor`, required\n",
    "            Model parameter to get accumulated gradeints for adam.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Создайте параметры для обучения логистической регрессии, сделаем Xavier ициализацию, которая выглядит следующим образом: \n",
    "\n",
    "$$w \\sim U[-\\frac{\\sqrt{6}}{\\sqrt{n_{in} + n_{out}}}, \\frac{\\sqrt{6}}{\\sqrt{n_{in} + n_{out}}}]$$\n",
    "\n",
    "где: \n",
    "\n",
    "* $n_{in}$ -- размер входа (в нейронах) \n",
    "* $n_{out}$ -- размер выхода (в нейронах)\n",
    "\n",
    "Подумайте над выбором $n_{in}$ и $n_{out}$ самостоятельно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = # your code here\n",
    "intercept = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = Adam([weights, intercept])\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные и создадим даталоадеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdcac1575fbc4b31b17ec2a03b7d0372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76e35e7bd52a4d6e9b734ff6736620bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04d456ebb82c4bdc82c400798a95d5d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f097832a69b64dffb0ffb34c804045c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\FashionMNIST\\raw\n",
      "Processing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\program files\\python37\\lib\\site-packages\\torchvision\\datasets\\mnist.py:469: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:141.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "fashion_mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    './data',\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    fashion_mnist_train, batch_size=4, shuffle=True, num_workers=1\n",
    ")\n",
    "\n",
    "fashion_mnist_eval = torchvision.datasets.FashionMNIST(\n",
    "    './data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    fashion_mnist_eval, batch_size=4, shuffle=True, num_workers=1\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию для тренировки логистической регрессии, она должна: \n",
    "    * Делать предсказания \n",
    "    * Считать лосс \n",
    "    * Подсчитывать градиенты\n",
    "    * Делать шаг оптимизации\n",
    "    * Обнулять посчитанные градиенты\n",
    "    * Считать метрики \n",
    "    * Возвращать полученные метрики\n",
    "    \n",
    "После этого предусмотрите возможность визуализировать метрики, чтобы нарисовать картинки, а именно от вас требуется визуализировать: \n",
    "\n",
    "    * Зависимость лосса от количества итераций\n",
    "    * Зависимость доли правильных ответов от количества итераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(weights, bias, batch, loss, optimizer):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 100):\n",
    "    for batch in train_dataloader:\n",
    "        metrics = train_logistic_regression(weights, bias, batch, loss, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопросы к секции: \n",
    "\n",
    "* Своими словами и без математики объясните благодаря чему Adam дает несмещенную оценку на квадрат градиента\n",
    "* Когда модель начала переобучаться? Как вы это поняли? Сделайте визуализацию и докажите свою точку зрения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Моя первая нейросеть (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной секции вам нужно сделать следующие вещи: \n",
    "\n",
    "* Реализовать три разных архитектуры нейросетей. Эти архитектуры должны принципиально отличаться друг от друга. Разрешается одной из архитекур брать полностью полносвязную модель. Остальные две должны быть сверточными и сильно отличаться друг от друга. К примеру, одна из таких архитектур может быть VGG подобная сеть, а другая ResNet подобная архитектура. \n",
    "\n",
    "* Написать цикл для обучения которым можно обучать все три модели без изменений кода\n",
    "\n",
    "* Попробовать каждую модель с двумя оптимизаторами: RMSprop и SGD with momentum\n",
    "\n",
    "* Визуализировать результаты перфоманса каждой модели (две метрики минимум для каждого сетапа, например, лосс и долю правильных ответов). В данном пункте мы ждем от вас визуализацию зависимости метрики от номера итерации обучения.\n",
    "\n",
    "* Сделать выводы какие были модели были лучше и как вы думаете почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, eval_dataloader, optimizer):\n",
    "    epoch = 0\n",
    "    for epoch in range(0, 11):\n",
    "        for x_train, y_train in tqdm(train_dataloader):\n",
    "            y_pred = model(x_train)\n",
    "            loss = nn.CrossEntropyLoss()(y_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            mean_val_loss = []\n",
    "            val_accuracy = []\n",
    "            with torch.no_grad():\n",
    "                for x_val, y_val in tqdm(eval_dataloader):\n",
    "                    y_pred = model(x_val)\n",
    "                    loss = nn.CrossEntropyLoss()(y_pred, y_val)\n",
    "                    mean_val_loss.append(loss.numpy())\n",
    "                    val_accuracy.extend((torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist())\n",
    "            print('Epoch: {epoch}, loss: {loss}, accuracy: {accuracy}'.format(\n",
    "                    epoch=epoch, loss=np.mean(mean_val_loss), accuracy=np.mean(val_accuracy)\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10),\n",
    "    nn.Softmax(dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:16<00:00, 897.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1178.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.80873441696167, accuracy: 0.6522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:18<00:00, 810.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:19<00:00, 779.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1175.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 1.7734640836715698, accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:19<00:00, 763.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:19<00:00, 759.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1163.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 1.9485480785369873, accuracy: 0.5123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:20<00:00, 733.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:19<00:00, 751.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1164.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss: 1.7605268955230713, accuracy: 0.7005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:19<00:00, 750.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:20<00:00, 725.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1154.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss: 1.7695995569229126, accuracy: 0.6914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:20<00:00, 732.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:20<00:00, 740.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1158.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 1.7683886289596558, accuracy: 0.6928\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model_1.parameters(), lr=0.05, momentum=0.9)\n",
    "train_model(model_1, train_dataloader, eval_dataloader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:22<00:00, 661.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1165.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.79244065284729, accuracy: 0.6685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:31<00:00, 481.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:33<00:00, 450.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1171.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 1.8544179201126099, accuracy: 0.6067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:34<00:00, 437.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:35<00:00, 427.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1172.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 1.8558132648468018, accuracy: 0.6054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:37<00:00, 405.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:38<00:00, 387.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1173.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss: 1.7615678310394287, accuracy: 0.6996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:40<00:00, 366.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:40<00:00, 369.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1167.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss: 1.7516474723815918, accuracy: 0.7095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:40<00:00, 385.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:40<00:00, 368.37it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 194.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 1.7713172435760498, accuracy: 0.6898\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.RMSprop(model_1.parameters())\n",
    "train_model(model_1, train_dataloader, eval_dataloader, optimizer)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
