{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашнее задание №1\n",
    "\n",
    "В этом домашнем задании вы познакомитесь с pytorch сами и сможете попрактиковаться в его применении. \n",
    "\n",
    "#### План:\n",
    "\n",
    "1. Простейшие операции в pytorch\n",
    "2. Пишем Adam и применяем его к ручной модели\n",
    "3. Обучаем свою первую нейросеть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простейшие операции на pytorch (2 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Cоздайте два случайных тензора (двумерных, не квадратных):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(4, 5)\n",
    "y = torch.rand(4, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Умножьте их друг на друга, результат запишите в третий тензор без использования оператора `=`, для создания третьего тензора предлагается использовать `torch.empty`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4357, 0.0395, 0.3623, 0.0337, 0.1157],\n",
       "        [0.2110, 0.0527, 0.0755, 0.0495, 0.0568],\n",
       "        [0.3947, 0.1399, 0.4843, 0.0305, 0.1105],\n",
       "        [0.0090, 0.2644, 0.9724, 0.2174, 0.0798]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = torch.empty(4, 5)\n",
    "torch.mul(x, y, out=z)\n",
    "z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Реализуйте ReLU используя только pytorch, примените его к тензору `x` (запрещено использование модулей torch.nn и его подмодулей, а также функции torch.relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_forward(x):\n",
    "    def func(x):\n",
    "        if x < 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    return x.apply_(func)\n",
    "        \n",
    "\n",
    "assert torch.all(F.relu(x) == relu_forward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Сделайте тоже самое c ELU (запрещено использование модулей torch.nn и его подмодулей):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elu_forward(x, alpha):\n",
    "    def func(x, alpha):\n",
    "        if x < 0:\n",
    "            return alpha * (exp(x) - 1)\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    return x.apply_(lambda x: func(x, alpha))\n",
    "    \n",
    "\n",
    "assert torch.allclose(\n",
    "    F.elu(x, 0.01),\n",
    "    elu_forward(x, 0.01), \n",
    "    1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: LeakyReLU (запрещено использование модулей torch.nn и его подмодулей):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lrelu_forward(x):\n",
    "    def func(x):\n",
    "        if x < 0:\n",
    "            return 0.01 * x\n",
    "        else:\n",
    "            return x\n",
    "    \n",
    "    return x.apply_(func)\n",
    "\n",
    "assert torch.all(F.leaky_relu(x) == lrelu_forward(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Теперь перейдем к немного более современным функциям активаций, например Mish, напомним как она выглядит:\n",
    "\n",
    "$$x * tanh(ln(1+e^x))$$\n",
    "\n",
    "(запрещено использование модулей torch.nn и его подмодулей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(x):\n",
    "    def func(x):\n",
    "        return x * math.tanh(math.log(1 + math.exp(x)))\n",
    "    \n",
    "    return x.apply_(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(\n",
    "    mish(torch.tensor([1, 1, 1], dtype=torch.float32)), \n",
    "    torch.tensor([0.8651, 0.8651, 0.8651]), \n",
    "    atol=1e-4\n",
    ")\n",
    "\n",
    "assert torch.allclose(\n",
    "    mish(torch.tensor([0.6376, 0.4021, 0.6656, 0.3726], dtype=torch.float64)), \n",
    "    torch.tensor([0.5014, 0.2908, 0.5280, 0.2663], dtype=torch.float64), \n",
    "    atol=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Теперь реализуем swish, напомним как она выглядит:\n",
    "\n",
    "$$x * \\sigma(x)$$\n",
    "\n",
    "(запрещено использование модулей torch.nn и его подмодулей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swish(x):\n",
    "    def func(x):\n",
    "        return x / (1 + math.exp(-x))\n",
    "    \n",
    "    return x.apply_(func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.allclose(\n",
    "    swish(torch.tensor([1, 1, 1], dtype=torch.float32)), \n",
    "    torch.tensor([0.7311, 0.7311, 0.7311]), \n",
    "    atol=1e-4\n",
    ")\n",
    "\n",
    "assert torch.allclose(\n",
    "    swish(torch.tensor([0.6376, 0.4021, 0.6656, 0.3726], dtype=torch.float64)), \n",
    "    torch.tensor([0.4171, 0.2409, 0.4396, 0.2206], dtype=torch.float64), \n",
    "    atol=1e-4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пишем Adam и применяем его к логистической регрессии (4 балла)\n",
    "\n",
    "\n",
    "В данной секции вам нужно сделать две вещи: \n",
    "\n",
    "1. Написать свой собственный оптимизатор подобно тому, который мы писали на семинаре\n",
    "2. Обучить логистическую регрессию побатчево на картинках из датасета \n",
    "\n",
    "\n",
    "#### Adam\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{eqnarray}\n",
    "g &=& \\frac{1}{m}\\nabla_w \\sum_i L(f(x_{i};w), y_{i}) \\\\\n",
    "m &=& \\beta_1 m + (1 - \\beta_1) g \\\\\n",
    "v &=& \\beta_2 v + (1 - \\beta_2) diag(gg^{T}) \\\\\n",
    "\\hat{m} &=& \\frac{m}{1 - \\beta_1^{t}} \\\\\n",
    "\\hat{v} &=& \\frac{v}{1 - \\beta_2^{t}} \\\\\n",
    "w &=& w - \\frac{\\eta}{\\sqrt{\\hat{v} + \\epsilon}} \\odot \\hat{m}\n",
    "\\end{eqnarray}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# абстрактный класс, не обращайте внимания\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "\n",
    "class InClassOptimizer(Optimizer):\n",
    "    def step(self):\n",
    "        \"\"\"Perform single optimization step.\"\"\"\n",
    "        with torch.no_grad(): # выключим градиенты\n",
    "            for group in self.param_groups:\n",
    "                self._group_step(group)\n",
    "\n",
    "    def _group_step(self, group):\n",
    "        # group ~ dict[str, ...]\n",
    "        \"\"\"\n",
    "        Private helper function to perform\n",
    "        single optimization step on model parameters.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Напишите свою реализацию Adam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Adam(InClassOptimizer):\n",
    "    def __init__(self, params, lr=0.001, eps=1e-13, beta_1=0.9, beta_2=0.999):\n",
    "        defaults = dict(lr=lr, eps=eps, beta_1=beta_1, beta_2=beta_2)\n",
    "        super().__init__(params, defaults)\n",
    "\n",
    "    def _group_step(self, group):\n",
    "        # One group contains information about values passed in init\n",
    "        # and model parameters to update\n",
    "        lr = group['lr']\n",
    "        eps = group['eps']\n",
    "        beta_1 = group['beta_1']\n",
    "        beta_2 = group['beta_2']\n",
    "        for param in filter(lambda x: x.grad is not None, group['params']):\n",
    "            pass\n",
    "\n",
    "    def _get_adam_buffer(self, param):\n",
    "        \"\"\"\n",
    "        Get accumulated gradients for Adam.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        param : `torch.Tensor`, required\n",
    "            Model parameter to get accumulated gradeints for Adagrad.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Accumulated Adam gradients for parameter.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def _init_adam_buffer(self, param):\n",
    "        \"\"\"\n",
    "        Initialize accumulated gradeints for adam.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        param : `torch.Tensor`, required\n",
    "            Model parameter to get accumulated gradeints for adam.\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task**: Создайте параметры для обучения логистической регрессии, сделаем Xavier ициализацию, которая выглядит следующим образом: \n",
    "\n",
    "$$w \\sim U[-\\frac{\\sqrt{6}}{\\sqrt{n_{in} + n_{out}}}, \\frac{\\sqrt{6}}{\\sqrt{n_{in} + n_{out}}}]$$\n",
    "\n",
    "где: \n",
    "\n",
    "* $n_{in}$ -- размер входа (в нейронах) \n",
    "* $n_{out}$ -- размер выхода (в нейронах)\n",
    "\n",
    "Подумайте над выбором $n_{in}$ и $n_{out}$ самостоятельно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-13-3f6fd89247ec>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-13-3f6fd89247ec>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    weights = # your code here\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "weights = # your code here\n",
    "intercept = # your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-1302a6971f09>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mintercept\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "optimizer = Adam([weights, intercept])\n",
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные и создадим даталоадеры:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist_train = torchvision.datasets.FashionMNIST(\n",
    "    './data',\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    fashion_mnist_train, batch_size=4, shuffle=True, num_workers=1\n",
    ")\n",
    "\n",
    "fashion_mnist_eval = torchvision.datasets.FashionMNIST(\n",
    "    './data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([transforms.ToTensor()])\n",
    ")\n",
    "\n",
    "eval_dataloader = torch.utils.data.DataLoader(\n",
    "    fashion_mnist_eval, batch_size=4, shuffle=True, num_workers=1\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите функцию для тренировки логистической регрессии, она должна: \n",
    "    * Делать предсказания \n",
    "    * Считать лосс \n",
    "    * Подсчитывать градиенты\n",
    "    * Делать шаг оптимизации\n",
    "    * Обнулять посчитанные градиенты\n",
    "    * Считать метрики \n",
    "    * Возвращать полученные метрики\n",
    "    \n",
    "После этого предусмотрите возможность визуализировать метрики, чтобы нарисовать картинки, а именно от вас требуется визуализировать: \n",
    "\n",
    "    * Зависимость лосса от количества итераций\n",
    "    * Зависимость доли правильных ответов от количества итераций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logistic_regression(weights, bias, batch, loss, optimizer):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-b53ed31e4af7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mmetrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_logistic_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'weights' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "    for batch in train_dataloader:\n",
    "        metrics = train_logistic_regression(weights, bias, batch, loss, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Вопросы к секции: \n",
    "\n",
    "* Своими словами и без математики объясните благодаря чему Adam дает несмещенную оценку на квадрат градиента\n",
    "* Когда модель начала переобучаться? Как вы это поняли? Сделайте визуализацию и докажите свою точку зрения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Моя первая нейросеть (4 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной секции вам нужно сделать следующие вещи: \n",
    "\n",
    "* Реализовать три разных архитектуры нейросетей. Эти архитектуры должны принципиально отличаться друг от друга. Разрешается одной из архитекур брать полностью полносвязную модель. Остальные две должны быть сверточными и сильно отличаться друг от друга. К примеру, одна из таких архитектур может быть VGG подобная сеть, а другая ResNet подобная архитектура. \n",
    "\n",
    "* Написать цикл для обучения которым можно обучать все три модели без изменений кода\n",
    "\n",
    "* Попробовать каждую модель с двумя оптимизаторами: RMSprop и SGD with momentum\n",
    "\n",
    "* Визуализировать результаты перфоманса каждой модели (две метрики минимум для каждого сетапа, например, лосс и долю правильных ответов). В данном пункте мы ждем от вас визуализацию зависимости метрики от номера итерации обучения.\n",
    "\n",
    "* Сделать выводы какие были модели были лучше и как вы думаете почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, eval_dataloader, optimizer):\n",
    "    epoch = 0\n",
    "    for epoch in range(0, 11):\n",
    "        for x_train, y_train in tqdm(train_dataloader):\n",
    "            y_pred = model(x_train)\n",
    "            loss = nn.CrossEntropyLoss()(y_pred, y_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        if epoch % 2 == 0:\n",
    "            mean_val_loss = []\n",
    "            val_accuracy = []\n",
    "            with torch.no_grad():\n",
    "                for x_val, y_val in tqdm(eval_dataloader):\n",
    "                    y_pred = model(x_val)\n",
    "                    loss = nn.CrossEntropyLoss()(y_pred, y_val)\n",
    "                    mean_val_loss.append(loss.numpy())\n",
    "                    val_accuracy.extend((torch.argmax(y_pred, dim=-1) == y_val).numpy().tolist())\n",
    "            print('Epoch: {epoch}, loss: {loss}, accuracy: {accuracy}'.format(\n",
    "                    epoch=epoch, loss=np.mean(mean_val_loss), accuracy=np.mean(val_accuracy)\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(784, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10),\n",
    "    nn.Softmax(dim=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=5)\n",
    "        self.conv3 = nn.Conv2d(32,64, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(3*3*64, 256)\n",
    "        self.fc2 = nn.Linear(256, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        #x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = F.relu(F.max_pool2d(self.conv3(x),2))\n",
    "        x = F.dropout(x, p=0.5, training=self.training)\n",
    "        x = x.view(-1,3*3*64 )\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MLP, self).__init__()\n",
    "        self.linear1 = nn.Linear(784,250)\n",
    "        self.linear2 = nn.Linear(250,100)\n",
    "        self.linear3 = nn.Linear(100,10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        X = F.relu(self.linear1(X))\n",
    "        X = F.relu(self.linear2(X))\n",
    "        X = self.linear3(X)\n",
    "        return F.log_softmax(X, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU()\n",
       "  (3): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (4): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (5): ReLU()\n",
       "  (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (7): Dropout(p=0.2, inplace=False)\n",
       "  (8): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (9): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (10): ReLU()\n",
       "  (11): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (12): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (13): ReLU()\n",
       "  (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (15): Dropout(p=0.2, inplace=False)\n",
       "  (16): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (17): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (18): ReLU()\n",
       "  (19): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (20): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (21): ReLU()\n",
       "  (22): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (23): Dropout(p=0.2, inplace=False)\n",
       "  (24): Flatten()\n",
       "  (25): Linear(in_features=576, out_features=128, bias=True)\n",
       "  (26): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (27): ReLU()\n",
       "  (28): Dropout(p=0.5, inplace=False)\n",
       "  (29): Linear(in_features=128, out_features=10, bias=True)\n",
       "  (30): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = nn.Sequential(\n",
    "    nn.Conv2d(1, 16, 3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16, 16, 3, padding=1),\n",
    "    nn.BatchNorm2d(16),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Dropout(0.2),\n",
    "\n",
    "    nn.Conv2d(16, 32, 3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(32, 32, 3, padding=1),\n",
    "    nn.BatchNorm2d(32),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Dropout(0.2),\n",
    "\n",
    "    nn.Conv2d(32, 64, 3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(64, 64, 3, padding=1),\n",
    "    nn.BatchNorm2d(64),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(2, 2),\n",
    "    nn.Dropout(0.2),\n",
    "\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(576, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.5),\n",
    "    nn.Linear(128, 10),\n",
    "    nn.Softmax()\n",
    ")\n",
    "model_3.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (linear1): Linear(in_features=784, out_features=250, bias=True)\n",
       "  (linear2): Linear(in_features=250, out_features=100, bias=True)\n",
       "  (linear3): Linear(in_features=100, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = CNN()\n",
    "model_2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:16<00:00, 897.96it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1178.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.80873441696167, accuracy: 0.6522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:18<00:00, 810.37it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:19<00:00, 779.54it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1175.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 1.7734640836715698, accuracy: 0.6875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:19<00:00, 763.26it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:19<00:00, 759.59it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1163.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 1.9485480785369873, accuracy: 0.5123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:20<00:00, 733.75it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:19<00:00, 751.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1164.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss: 1.7605268955230713, accuracy: 0.7005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:19<00:00, 750.20it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:20<00:00, 725.32it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1154.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss: 1.7695995569229126, accuracy: 0.6914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:20<00:00, 732.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:20<00:00, 740.77it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1158.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 1.7683886289596558, accuracy: 0.6928\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.SGD(model_1.parameters(), lr=0.05, momentum=0.9)\n",
    "train_model(model_1, train_dataloader, eval_dataloader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:22<00:00, 661.06it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1165.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, loss: 1.79244065284729, accuracy: 0.6685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:31<00:00, 481.53it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:33<00:00, 450.68it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1171.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, loss: 1.8544179201126099, accuracy: 0.6067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:34<00:00, 437.31it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:35<00:00, 427.47it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1172.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, loss: 1.8558132648468018, accuracy: 0.6054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:37<00:00, 405.14it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:38<00:00, 387.73it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1173.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, loss: 1.7615678310394287, accuracy: 0.6996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:40<00:00, 366.04it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:40<00:00, 369.88it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 1167.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, loss: 1.7516474723815918, accuracy: 0.7095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:40<00:00, 385.92it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 15000/15000 [00:40<00:00, 368.37it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████| 2500/2500 [00:02<00:00, 194.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss: 1.7713172435760498, accuracy: 0.6898\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.RMSprop(model_1.parameters())\n",
    "train_model(model_1, train_dataloader, eval_dataloader, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, train_dataloader, test_dataloader):\n",
    "    train_loss_log = []\n",
    "    train_acc_log = []\n",
    "    val_loss_log = []\n",
    "    val_acc_log = []\n",
    "    \n",
    "    for epoch in range(25):\n",
    "        model.train()\n",
    "        train_loss = 0.\n",
    "        train_size = 0\n",
    "        train_acc = 0.\n",
    "        for imgs, labels in train_dataloader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            imgs = imgs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            y_pred = model(imgs)\n",
    "\n",
    "            loss = criterion(y_pred, labels)\n",
    "            loss.backward()\n",
    "            train_loss += loss.item()\n",
    "            train_size += y_pred.size(0)\n",
    "            train_loss_log.append(loss.data / y_pred.size(0))\n",
    "\n",
    "            _, pred_classes = torch.max(y_pred, 1)\n",
    "            train_acc += (pred_classes == labels).sum().item()\n",
    "            train_acc_log.append(np.mean((pred_classes == labels).cpu().numpy()))\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "        val_loss = 0.\n",
    "        val_size = 0\n",
    "        val_acc = 0.\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for imgs, labels in test_dataloader:\n",
    "                imgs = imgs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                \n",
    "                pred = model(imgs)\n",
    "                loss = criterion(pred, labels)\n",
    "                val_loss += loss.item()\n",
    "                val_size += pred.size(0)\n",
    "\n",
    "                _, pred_classes = torch.max(pred, 1)\n",
    "                val_acc += (pred_classes == labels).sum().item()\n",
    "        val_loss_log.append(val_loss / val_size)\n",
    "        val_acc_log.append(val_acc / val_size)\n",
    "\n",
    "        clear_output()\n",
    "        plot_history(train_loss_log, val_loss_log, 'loss')\n",
    "        plot_history(train_acc_log, val_acc_log, 'accuracy')\n",
    "\n",
    "        print('Train loss:', train_loss / train_size)\n",
    "        print('Train acc:', train_acc / train_size)\n",
    "        print('Val loss:', val_loss / val_size)\n",
    "        print('Val acc:', val_acc / val_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "def plot_history(train_history, val_history, title='loss'):\n",
    "    plt.figure()\n",
    "    plt.title('{}'.format(title))\n",
    "    plt.plot(train_history, label='train', zorder=1)\n",
    "    \n",
    "    points = np.array(val_history)\n",
    "    steps = list(range(0, len(train_history) + 1, int(len(train_history) / len(val_history))))[1:]\n",
    "    \n",
    "    plt.scatter(steps, val_history, marker='+', s=180, c='orange', label='val', zorder=2)\n",
    "    plt.xlabel('train steps')\n",
    "    \n",
    "    plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 dim 1 must match mat2 dim 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-17ab275c6028>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-7cab5def9c87>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, criterion, optimizer, train_dataloader, test_dataloader)\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-2373fd52a739>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1674\u001b[0m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1675\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1676\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1677\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1678\u001b[0m             \u001b[0moutput\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: mat1 dim 1 must match mat2 dim 0"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model_2.parameters(), lr=0.001, momentum=0.9)\n",
    "train(model_2, criterion, optimizer, train_dataloader, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.5195795567532381\n",
      "Train acc: 0.38256666666666667\n",
      "Val loss: 0.5047453164458274\n",
      "Val acc: 0.4419\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-98f502438e0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meval_dataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-9-7cab5def9c87>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, criterion, optimizer, train_dataloader, test_dataloader)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mtrain_size\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m         \"\"\"\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 127\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    128\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model_3.parameters())\n",
    "train(model_3, criterion, optimizer, train_dataloader, eval_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (32x1x1). Calculated output size: (32x0x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-03b3a60de181>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\container.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    118\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\modules\\pooling.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m         return F.max_pool2d(input, self.kernel_size, self.stride,\n\u001b[0;32m    158\u001b[0m                             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mceil_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 159\u001b[1;33m                             self.return_indices)\n\u001b[0m\u001b[0;32m    160\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\_jit_internal.py\u001b[0m in \u001b[0;36mfn\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    245\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mif_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mif_false\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files\\python37\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36m_max_pool2d\u001b[1;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[0;32m    574\u001b[0m         \u001b[0mstride\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mannotate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m     return torch.max_pool2d(\n\u001b[1;32m--> 576\u001b[1;33m         input, kernel_size, stride, padding, dilation, ceil_mode)\n\u001b[0m\u001b[0;32m    577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m max_pool2d = boolean_dispatch(\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given input size: (32x1x1). Calculated output size: (32x0x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "model_3(torch.ones(16, 1, 3, 3).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 576])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3(list(eval_dataloader)[0][0].to(device)).shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
